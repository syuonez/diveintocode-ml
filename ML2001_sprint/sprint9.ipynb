{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習　デープニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import copy\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "#X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crossentropy(final_answer, mini_y_train):\n",
    "    return -np.sum(mini_y_train * np.log(final_answer))/(final_answer.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchSimpleNeuralNetrowkClassifier():\n",
    "    \"\"\"\n",
    "    シンプルな三層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "    def __init__(self, verbose = True):\n",
    "        \n",
    "        self.n_nodes1 = 400 # 1層目のノード数\n",
    "        self.n_nodes2 = 200 # 2層目のノード数\n",
    "        self.n_output = 10 # 出力のクラス数（3層目のノード数）\n",
    "        self.sigma = 0.01 # ガウス分布の標準偏差\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        self.verbose = verbose\n",
    "        pass\n",
    "    def fit(self, X, y, X_val=None, y_val=None, val=False):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証データの正解値\n",
    "        \"\"\"\n",
    "        \n",
    "        self.W1 = self.sigma * np.random.randn(X.shape[1], self.n_nodes1)\n",
    "        self.B1 = self.sigma * np.random.randn(self.n_nodes1,)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        self.B2 = self.sigma * np.random.randn(self.n_nodes2, )\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "        self.B3 = self.sigma * np.random.randn(self.n_output, )\n",
    "        \n",
    "       \n",
    "        \n",
    "        \n",
    "        #エポック毎の損失を記録\n",
    "        self.cost = [] \n",
    "        self.cost_val = []\n",
    "        \n",
    "        self.epoch=20 #何回回すか\n",
    "        self.alpha = 0.001#学習率\n",
    "        \n",
    "        self.hako = []\n",
    "        self.count = []\n",
    "        \n",
    "        #全データ１回分の処理\n",
    "        for i in range(self.epoch):\n",
    "            get_mini_batch = GetMiniBatch(X_train, y_train, batch_size=20)\n",
    "           \n",
    "                \n",
    "                \n",
    "            #バッチ毎の処理\n",
    "\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:#2400回\n",
    "                \n",
    "                #フォアード\n",
    "                A1 = np.dot(mini_X_train, self.W1) + self.B1\n",
    "                Z1 = self.tanh(A1)\n",
    "                A2 = np.dot(Z1, self.W2) + self.B2\n",
    "                Z2 = self.tanh(A2)\n",
    "                A3 = np.dot(Z2, self.W3) + self.B3\n",
    "                final_answer = self.softmax(A3)\n",
    "                #バックプロパゲーション\n",
    "                delta1 = final_answer - mini_y_train\n",
    "                delta2 = (1 - np.tanh(A2)**2) * (np.dot(delta1,self.W3.T))###(np.dot(delta1,self.W3.T)) = dz\n",
    "                delta3 = (1 - np.tanh(A1)**2) * (np.dot(delta2,self.W2.T))\n",
    "                #print(delta3.shape)\n",
    "                #layer3\n",
    "                b3grad = delta1\n",
    "                W3grad = np.dot(Z2.T,delta1)\n",
    "                #layer2\n",
    "                b2grad = delta2\n",
    "                W2grad = np.dot(Z1.T,delta2)\n",
    "                #layer1\n",
    "                b1grad = delta3\n",
    "                W1grad =np.dot(mini_X_train.T,delta3)\n",
    "                W1grad.shape\n",
    "                #更新\n",
    "#                 print(np.mean(b3grad,axis=0).shape)\n",
    "#                 print(self.B3.shape)\n",
    "                self.B3 -= self.alpha*np.mean(b3grad,axis=0)\n",
    "                self.W3 -= self.alpha*W3grad\n",
    "#                 print(np.mean(b2grad,axis=0).shape)\n",
    "#                 print(self.B2.shape)\n",
    "                self.B2 -= self.alpha*np.mean(b2grad,axis=0)\n",
    "                self.W2 -= self.alpha*W2grad\n",
    "#                 print(np.mean(b1grad,axis=0).shape)\n",
    "#                 print(self.B1.shape)\n",
    "                self.B1 -= self.alpha*np.mean(b1grad,axis=0)\n",
    "                self.W1 -= self.alpha*W1grad\n",
    "            \n",
    "       #フォアード\n",
    "            A1 = np.dot(X_train, self.W1) + self.B1\n",
    "            Z1 = self.tanh(A1)\n",
    "            A2 = np.dot(Z1, self.W2) + self.B2\n",
    "            Z2 = self.tanh(A2)\n",
    "            A3 = np.dot(Z2, self.W3) + self.B3\n",
    "            final_answer = self.softmax(A3)     \n",
    "\n",
    "                \n",
    "            self.cost.append(crossentropy(final_answer, y_train))\n",
    "            \n",
    "            \n",
    "            if val:\n",
    "                A1 = np.dot(X_val, self.W1) + self.B1\n",
    "                Z1 = self.tanh(A1)\n",
    "                A2 = np.dot(Z1, self.W2) + self.B2\n",
    "                Z2 = self.tanh(A2)\n",
    "                A3 = np.dot(Z2, self.W3) + self.B3\n",
    "                final_val_answer = self.softmax(A3)  \n",
    "                \n",
    "                self.cost_val.append(crossentropy(final_val_answer, y_val))\n",
    "                \n",
    "                \n",
    "                \n",
    "        if self.verbose:\n",
    "            #verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        A1 = np.dot(X, self.W1) + self.B1\n",
    "        Z1 = self.tanh(A1)\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\n",
    "        Z2 = self.tanh(A2)\n",
    "        A3 = np.dot(Z2, self.W3) + self.B3\n",
    "        pre_final_answer = self.softmax(A3)\n",
    "        pre_final_answer_answer = np.argmax(pre_final_answer, axis=1)\n",
    "        return pre_final_answer_answer\n",
    "    \n",
    "    def tanh(self, A):\n",
    "        return (np.exp(A) - np.exp(-A))/(np.exp(A) + np.exp(-A))\n",
    "    \n",
    "    def softmax(self, A3):\n",
    "        A3 = A3.T\n",
    "        ue = np.exp(A3)\n",
    "        shita = np.sum(np.exp(A3), axis = 0)\n",
    "        return (ue/shita).T\n",
    "    \n",
    "    def crossentropy(self, final_answer, mini_y_train):\n",
    "        return -np.sum(mini_y_train * np.log(final_answer))/(final_answer.shape[0])\n",
    "    \n",
    "        return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】全結合層のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "全結合層のクラス化を行なってください。\n",
    "\n",
    "\n",
    "以下に雛形を載せました。コンストラクタで重みやバイアスの初期化をして、あとはフォワードとバックワードのメソッドを用意します。重みW、バイアスB、およびフォワード時の入力Xをインスタンス変数として保持しておくことで、煩雑な入出力は不要になります。\n",
    "\n",
    "\n",
    "なお、インスタンスも引数として渡すことができます。そのため、初期化方法のインスタンスinitializerをコンストラクタで受け取れば、それにより初期化が行われます。渡すインスタンスを変えれば、初期化方法が変えられます。\n",
    "\n",
    "\n",
    "また、引数として自身のインスタンスselfを渡すこともできます。これを利用してself.optimizer.update(self)という風に層の重みの更新が可能です。更新に必要な値は複数ありますが、全て全結合層が持つインスタンス変数にすることができます。\n",
    "\n",
    "\n",
    "初期化方法と最適化手法のクラスについては後述します。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】初期化方法のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】最適化手法のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イテレーションごとのフォワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "A1 = self.FC1.forward(X)\n",
    "Z1 = self.activation1.forward(A1) #Tanh().forward()\n",
    "A2 = self.FC2.forward(Z1)\n",
    "Z2 = self.activation2.forward(A2)\n",
    "A3 = self.FC3.forward(Z2)\n",
    "Z3 = self.activation3.forward(A3)\n",
    "\n",
    " #フォアード\n",
    "\"\"\"\"\"\n",
    "A1 = np.dot(mini_X_train, self.W1) + self.B1\n",
    "Z1 = self.tanh(A1)\n",
    "A2 = np.dot(Z1, self.W2) + self.B2\n",
    "Z2 = self.tanh(A2)\n",
    "A3 = np.dot(Z2, self.W3) + self.B3\n",
    "final_answer(Z3) = self.softmax(A3)\n",
    "\"\"\"\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "イテレーションごとのバックワード"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dA3 = self.activation3.backward(Z3, Y) # 交差エントロピー誤差とソフトマックスを合わせている???????\n",
    "dZ2 = self.FC3.backward(dA3)\n",
    "dA2 = self.activation2.backward(dZ2)\n",
    "dZ1 = self.FC2.backward(dA2)\n",
    "dA1 = self.activation1.backward(dZ1)\n",
    "dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "\n",
    "\"\"\"\"\n",
    "バックプロパゲーション\n",
    "delta1 = final_answer - mini_y_train\n",
    "delta2 = (1 - np.tanh(A2)**2) * (np.dot(delta1,self.W3.T))\n",
    "delta3 = (1 - np.tanh(A1)**2) * (np.dot(delta2,self.W2.T))\n",
    "\"\"\"\"\"\"\n",
    "#layer3\n",
    "b3grad = delta1\n",
    "W3grad = np.dot(Z2.T,delta1)\n",
    "#layer2\n",
    "b2grad = delta2\n",
    "W2grad = np.dot(Z1.T,delta2)\n",
    "#layer1\n",
    "b1grad = delta3\n",
    "W1grad =np.dot(mini_X_train.T,delta3)\n",
    "W1grad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        self.optimizer = optimizer\n",
    "        \n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B =  initializer.B(n_nodes2)\n",
    "        \"\"\"\"\n",
    "        self.W1 = self.sigma * np.random.randn(X.shape[1], self.n_nodes1)\n",
    "        self.W2 = self.sigma * np.random.randn(self.n_nodes1, self.n_nodes2)\n",
    "        self.W3 = self.sigma * np.random.randn(self.n_nodes2, self.n_output)\n",
    "        self.B1 = self.sigma * np.random.randn(self.n_nodes1,)\n",
    "        self.B2 = self.sigma * np.random.randn(self.n_nodes2, )\n",
    "        self.B3 = self.sigma * np.random.randn(self.n_output, )\n",
    "        \"\"\"\"\"\n",
    "        pass\n",
    "    def forward(self, Z):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        Z : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\" \n",
    "        self.Z = Z.copy()\n",
    "        \n",
    "        return np.dot(Z, self.W) + self.B #output=A\n",
    "        \n",
    "        \"\"\"\"\"\n",
    "        A1 = np.dot(mini_X_train, self.W1) + self.B1\n",
    "        Z1 = self.tanh(A1)\n",
    "        A2 = np.dot(Z1, self.W2) + self.B2\n",
    "        Z2 = self.tanh(A2) \n",
    "        A3 = np.dot(Z2, self.W3) + self.B3\n",
    "        final_answer = self.softmax(A3)\n",
    "        \"\"\"\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dB = dA #b3grad = delta1=dA\n",
    "        #print(self.Z.shape)\n",
    "        #print(dA.shape)\n",
    "        self.dW = np.dot(self.Z.T,dA) #np.dot(___Z2___, dA)shapedW?? = np.dot(self.Z,dA) のshape確認\n",
    "        \n",
    "        dZ = np.dot(dA, self.W.T)#(np.dot(delta1,self.W3.T)\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self) #??????\n",
    "        return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 問題4】活性化関数のクラス化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "活性化関数のクラス化を行なってください。\n",
    "\n",
    "\n",
    "ソフトマックス関数のバックプロパゲーションには交差エントロピー誤差の計算も含む実装を行うことで計算が簡略化されます。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tanh:\n",
    "    def __init__(self):\n",
    "        self.A = None\n",
    "        \n",
    "    def forward(self, A):\n",
    "        self.A = A\n",
    "        return (np.exp(self.A) - np.exp(-self.A))/(np.exp(self.A) + np.exp(-self.A))\n",
    "    \n",
    "    def backward(self, dZ):\n",
    "        return dZ*(1 - self.forward(self.A)**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleInitializer:\n",
    "    def __init__(self, sigma):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2 ):\n",
    "        return self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        return  self.sigma * np.random.randn(n_nodes2)\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Softmax_with_crossentropyloss():\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def forward(self,A):\n",
    "        A = A.T\n",
    "        ue = np.exp(A)\n",
    "        shita = np.sum(np.exp(A), axis = 0)\n",
    "        self.Z_final = (ue/shita).T\n",
    "        return self.Z_final\n",
    "    \n",
    "    def backward(self,y):\n",
    "        return self.Z_final - y#正解ラベル\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "    \n",
    "    def update(self, layer):#FCのインスタンス入る self? layer.W→self.W?\n",
    "        layer.W = layer.W - self.alpha * layer.dW\n",
    "        #layer.B = layer.B - self.alpha * layer.dB.mean(axis=1)\n",
    "        layer.B = layer.B - self.alpha *np.mean( layer.dB,axis=0)\n",
    "        return layer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題5】ReLUクラスの作成"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "現在一般的に使われている活性化関数であるReLU（Rectified Linear Unit）をReLUクラスとして実装してください。\n",
    "\n",
    "\n",
    "ReLUは以下の数式です。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "% <![CDATA[\n",
    "f(x) = ReLU(x) = \\begin{cases}\n",
    "x  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x\n",
    " : ある特徴量。スカラー\n",
    "\n",
    "\n",
    "実装上はnp.maximumを使い配列に対してまとめて計算が可能です。\n",
    "\n",
    "\n",
    "numpy.maximum — NumPy v1.15 Manual\n",
    "\n",
    "\n",
    "一方、バックプロパゲーションのための \n",
    "x\n",
    " に関する \n",
    "f\n",
    "(\n",
    "x\n",
    ")\n",
    " の微分は以下のようになります。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "% <![CDATA[\n",
    "\\frac{\\partial f(x)}{\\partial x} = \\begin{cases}\n",
    "1  & \\text{if $x>0$,}\\\\\n",
    "0 & \\text{if $x\\leqq0$.}\n",
    "\\end{cases} %]]>\n",
    "$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "数学的には微分可能ではないですが、 \n",
    "x\n",
    "=\n",
    "0\n",
    " のとき \n",
    "0\n",
    " とすることで対応しています。\n",
    "\n",
    "\n",
    "フォワード時の \n",
    "x\n",
    " の正負により、勾配を逆伝播するかどうかが決まるということになります。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def __init__(self):\n",
    "        pass\n",
    "    def forward(self, X):\n",
    "        self.mask = np.where(X>0, 1, 0)\n",
    "        \n",
    "        return np.maximum(0, X)\n",
    "    \n",
    "    def backward(self, X):\n",
    "        X = X*self.mask\n",
    "        return X\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class reluuuuuu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "    \n",
    "    def forward(self, x):\n",
    "        self.mask = (x <=0)\n",
    "        out = x.copy()\n",
    "        out[self.mask]= 0\n",
    "        \n",
    "        return out\n",
    "\n",
    "    def backward(self, dout):\n",
    "        dout[self.mask]= 0\n",
    "        dx = dout\n",
    "        \n",
    "        return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ooo = np.arange(10).reshape([5,2])\n",
    "ooo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reluu = ReLU()\n",
    "reluu.forward(ooo)\n",
    "reluu.backward(ooo)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shita= np.random.randn(3, 3)\n",
    "shita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reluoo = reluuuuuu()\n",
    "reluoo.forward(shita)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (shita <=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shita[mask]=0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題6】重みの初期値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "シグモイド関数やハイパボリックタンジェント関数のときは Xavierの初期値 （またはGlorotの初期値）、ReLUのときは Heの初期値 が使われます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Xavierの初期値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Xavierの初期値における標準偏差 \n",
    "σ\n",
    " は次の式で求められます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\sigma = \\frac{1}{\\sqrt{n}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavierをインスタンス化するときはXavier(self.n_nodes)とする\n",
    "\n",
    "class Xavier:\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.n_nodes1= n_nodes1\n",
    "        self.sigma = 1/np.sqrt(self.n_nodes1)\n",
    "               \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        return self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        return  self.sigma * np.random.randn(n_nodes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Heの初期値"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Heの初期値における標準偏差 \n",
    "σ\n",
    " は次の式で求められます。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "\\sigma = \\sqrt{\\frac{2}{n}}\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Heをインスタンス化するときはXavier(self.n_nodes)とする\n",
    "class He:\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.n_nodes1= n_nodes1\n",
    "        self.sigma = np.sqrt(2/self.n_nodes1)\n",
    "        \n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        return self.sigma*np.random.randn(n_nodes1, n_nodes2)\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        return  self.sigma * np.random.randn(n_nodes2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題7】最適化手法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$\n",
    "H_i^{\\prime}  = H_i+E(\\frac{\\partial L}{\\partial W_i})×E(\\frac{\\partial L}{\\partial W_i})\\\\<br/>W_i^{\\prime} = W_i - \\alpha \\frac{1}{\\sqrt{H_i^{\\prime} }} E(\\frac{\\partial L}{\\partial W_i}) \\\\\n",
    "$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AdaGrad:\n",
    "    def __init__(self, alpha):\n",
    "        self.alpha = alpha\n",
    "        self.h_W = 0\n",
    "        self.h_B = 0\n",
    "        \n",
    "    def update(self, layer):#FCのインスタンス入る self? layer.W→self.W?\n",
    "        self.h_W = self.h_W + (layer.dW* layer.dW)\n",
    "        self.h_B = self.h_B + (np.mean(layer.dB,axis=0)* np.mean(layer.dB,axis=0))\n",
    "        layer.W = layer.W - (self.alpha*np.sqrt(1/self.h_W)) * layer.dW\n",
    "        #layer.B = layer.B - self.alpha * layer.dB.mean(axis=1)\n",
    "        layer.B = layer.B - (self.alpha*np.sqrt(1/self.h_B)) *np.mean(layer.dB,axis=0)\n",
    "        #print(layer.B.shape)\n",
    "        return layer\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】クラスの完成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrachDeepNeuralNetworkRegressor():\n",
    "    \n",
    "    def __init__(self, n_epochs, batch, alpha = np.exp(-7), sigma = 0.01, n_nodes1 = 400, n_nodes2 = 200, n_output = 10):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch = batch\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.loss = []#np.zeros(n_epochs)\n",
    "        self.val_loss = []#np.zeros(n_epochs)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None, val=False):\n",
    "        #y = y[:, np.newaxis]\n",
    "        \n",
    "       # y_val = y_val[:,np.newaxis]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.n_features = self.X.shape[1]\n",
    "        train_minibatch = GetMiniBatch(self.X, y, self.batch)\n",
    "        test_minibatch = GetMiniBatch(X_val, y_val, self.batch)\n",
    "        \n",
    "        optimizer = SGD(self.alpha)\n",
    "        #optimizer1 = AdaGrad(self.alpha)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer1)\n",
    "        #self.activation1 = Tanh()\n",
    "        self.activation1 = ReLU()\n",
    "        #optimizer2 = AdaGrad(self.alpha)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer2)\n",
    "        #self.activation2 = Tanh()\n",
    "        self.activation2 = ReLU()\n",
    "        #optimizer3 = AdaGrad(self.alpha)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer3)\n",
    "        self.activation3 = Softmax_with_crossentropyloss()\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            for mini_X, mini_y in train_minibatch:\n",
    "                X = mini_X\n",
    "                y = mini_y#[:,np.newaxis] ############\n",
    "                #フォワード\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1) #Tanh().forward()\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                #バックワード\n",
    "                dA3 = self.activation3.backward(y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "            \n",
    "            print(self.X.shape)\n",
    "            A4 = self.FC1.forward(self.X)\n",
    "            print(A4.shape)\n",
    "            Z4 = self.activation1.forward(A4)\n",
    "            A5 = self.FC2.forward(Z4)\n",
    "            Z5 = self.activation2.forward(A5)\n",
    "            A6 = self.FC3.forward(Z5)\n",
    "            Z6 = self.activation3.forward(A6)\n",
    "            print(Z6.shape)\n",
    "            print(self.y.shape)\n",
    "            print(self.crossentropy(Z6, self.y))\n",
    "            self.loss.append(self.crossentropy(Z6, self.y))####?\n",
    "            \n",
    "#             print(self.X.shape)\n",
    "#             A1 = self.FC1.forward(self.X)\n",
    "#             print(A1)\n",
    "#             Z1 = self.activation1.forward(A1)\n",
    "#             A2 = self.FC2.forward(Z1)\n",
    "#             Z2 = self.activation2.forward(A2)\n",
    "#             A3 = self.FC3.forward(Z2)\n",
    "#             Z3 = self.activation3.forward(A3)\n",
    "#             print(Z3)\n",
    "#             print(y)\n",
    "#             print(self.crossentropy(Z3, y))\n",
    "#             self.loss.append(self.crossentropy(Z3, y))####?\n",
    "            \n",
    "            \n",
    "            if val:\n",
    "                A_val1 = self.FC1.forward(X_val)\n",
    "                Z_val1 = self.activation1.forward(A_val1)\n",
    "                A_val3 = self.FC2.forward(Z_val1)\n",
    "                Z_val2 = self.activation2.forward(A_val3)\n",
    "                A_val3 = self.FC3.forward(Z_val2)\n",
    "                Z_val3 = self.activation3.forward(A_val3)\n",
    "\n",
    "                self.val_loss.append(self.crossentropy(Z_val3, y_val))\n",
    "            \n",
    "                \n",
    "    def predict(self, X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1) #X,self.X\n",
    "        #print(Z1.shape)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "                #print(A2.shape)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "                #print(Z2.shape)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "                #print(A3.shape)\n",
    "        pre_final_answer = self.activation3.forward(A3)\n",
    "        pre_final_answer_answer = np.argmax(pre_final_answer, axis=1)\n",
    "        return pre_final_answer_answer\n",
    "    \n",
    "    def crossentropy(self, final_answer, y):\n",
    "        return -np.sum(y * np.log(final_answer))/(final_answer.shape[0])\n",
    "        \n",
    "                \n",
    "        \n",
    "                \n",
    "        return\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "dnnr = ScrachDeepNeuralNetworkRegressor(n_epochs=15, batch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.5585617583392231\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.32817041845886796\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.2398582959773998\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.17905904427050254\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.14168907383741053\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.11560717536778242\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.09692549525374275\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.08228833610274441\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.07049009658763745\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.0610579980118431\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.05324085897370648\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.04652248147116744\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.04100598938251051\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.03611720561813446\n",
      "(48000, 784)\n",
      "(48000, 400)\n",
      "(48000, 10)\n",
      "(48000, 10)\n",
      "0.03209396226577688\n"
     ]
    }
   ],
   "source": [
    "dnnr.fit(X_train, y_train, X_val, y_val, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(400,)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnr.FC1.B.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_y = dnnr.predict(X_val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 1, 4, ..., 6, 0, 5])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12000, 10)"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_box = np.zeros((len(predict_y),10),dtype=int)\n",
    "predict_box.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "for v in range(len(predict_y)):\n",
    "    predict_box[v,predict_y[v]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_box"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9755"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Accuracy###\n",
    "accuracy_score(y_val, predict_box)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題9】学習と推定"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "層の数や活性化関数を変えたいくつかのネットワークを作成してください。そして、MNISTのデータを学習・推定し、Accuracyを計算してください。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5585617583392231,\n",
       " 0.32817041845886796,\n",
       " 0.2398582959773998,\n",
       " 0.17905904427050254,\n",
       " 0.14168907383741053,\n",
       " 0.11560717536778242,\n",
       " 0.09692549525374275,\n",
       " 0.08228833610274441,\n",
       " 0.07049009658763745,\n",
       " 0.0610579980118431,\n",
       " 0.05324085897370648,\n",
       " 0.04652248147116744,\n",
       " 0.04100598938251051,\n",
       " 0.03611720561813446,\n",
       " 0.03209396226577688]"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnr.loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.5603941482520077,\n",
       " 0.332011099583898,\n",
       " 0.24853984913202035,\n",
       " 0.19334336705915586,\n",
       " 0.16098326427426543,\n",
       " 0.13911149999612635,\n",
       " 0.12397388452544131,\n",
       " 0.1130578946905548,\n",
       " 0.10501375218272259,\n",
       " 0.09942885495296838,\n",
       " 0.09526663739625693,\n",
       " 0.09236381339711448,\n",
       " 0.09048471093014884,\n",
       " 0.08914225304408074,\n",
       " 0.08844310143929006]"
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dnnr.val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "x=list(range(dnnr.n_epochs))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(x,dnnr.loss, label='train')\n",
    "plt.scatter(x, dnnr.val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrachDeepNeuralNetworkRegressor2():\n",
    "    \n",
    "    def __init__(self, n_epochs, batch, alpha = np.exp(-7), sigma = 0.01, n_nodes1 = 400, n_nodes2 = 200, n_output = 10):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch = batch\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.loss = []#np.zeros(n_epochs)\n",
    "        self.val_loss = []#np.zeros(n_epochs)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None, val=False):\n",
    "        #y = y[:, np.newaxis]\n",
    "        \n",
    "       # y_val = y_val[:,np.newaxis]\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        \n",
    "        self.n_features = self.X.shape[1]\n",
    "        train_minibatch = GetMiniBatch(self.X, y, self.batch)\n",
    "        test_minibatch = GetMiniBatch(X_val, y_val, self.batch)\n",
    "        \n",
    "        optimizer = SGD(self.alpha)\n",
    "        #optimizer1 = AdaGrad(self.alpha)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, Xavier(self.n_nodes1), optimizer)\n",
    "        #self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer1)\n",
    "        self.activation1 = Tanh()\n",
    "        #self.activation1 = ReLU()\n",
    "        #optimizer2 = AdaGrad(self.alpha)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, Xavier(self.n_nodes1), optimizer)\n",
    "        #self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer2)\n",
    "        self.activation2 = Tanh()\n",
    "        #self.activation2 = ReLU()\n",
    "        #optimizer3 = AdaGrad(self.alpha)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, Xavier(self.n_nodes1), optimizer)\n",
    "        #self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer3)\n",
    "        self.activation3 = Softmax_with_crossentropyloss()\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            for mini_X, mini_y in train_minibatch:\n",
    "                X = mini_X\n",
    "                y = mini_y#[:,np.newaxis] ############\n",
    "                #フォワード\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1) #Tanh().forward()\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                #バックワード\n",
    "                dA3 = self.activation3.backward(y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "            \n",
    "\n",
    "            A4 = self.FC1.forward(self.X)\n",
    "            Z4 = self.activation1.forward(A4)\n",
    "            A5 = self.FC2.forward(Z4)\n",
    "            Z5 = self.activation2.forward(A5)\n",
    "            A6 = self.FC3.forward(Z5)\n",
    "            Z6 = self.activation3.forward(A6)\n",
    "\n",
    "            self.loss.append(self.crossentropy(Z6, self.y))\n",
    "\n",
    "            \n",
    "            if val:\n",
    "                A_val1 = self.FC1.forward(X_val)\n",
    "                Z_val1 = self.activation1.forward(A_val1)\n",
    "                A_val3 = self.FC2.forward(Z_val1)\n",
    "                Z_val2 = self.activation2.forward(A_val3)\n",
    "                A_val3 = self.FC3.forward(Z_val2)\n",
    "                Z_val3 = self.activation3.forward(A_val3)\n",
    "\n",
    "                self.val_loss.append(self.crossentropy(Z_val3, y_val))\n",
    "            \n",
    "                \n",
    "    def predict(self, X):\n",
    "        A1 = self.FC1.forward(X)\n",
    "        Z1 = self.activation1.forward(A1) #X,self.X\n",
    "        #print(Z1.shape)\n",
    "        A2 = self.FC2.forward(Z1)\n",
    "                #print(A2.shape)\n",
    "        Z2 = self.activation2.forward(A2)\n",
    "                #print(Z2.shape)\n",
    "        A3 = self.FC3.forward(Z2)\n",
    "                #print(A3.shape)\n",
    "        pre_final_answer = self.activation3.forward(A3)\n",
    "        pre_final_answer_answer = np.argmax(pre_final_answer, axis=1)\n",
    "        return pre_final_answer_answer\n",
    "    \n",
    "    def crossentropy(self, final_answer, y):\n",
    "        return -np.sum(y * np.log(final_answer))/(final_answer.shape[0])\n",
    "        \n",
    "                \n",
    "        \n",
    "                \n",
    "        return\n",
    "            \n",
    "                \n",
    "                \n",
    "                \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {},
   "outputs": [],
   "source": [
    "snnr_xavier = ScrachDeepNeuralNetworkRegressor2(n_epochs=15, batch=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "snnr_xavier.fit(X_train, y_train, X_val, y_val, val=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_xavier_y = snnr_xavier.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 198,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_xavierbox = np.zeros((len(predict_xavier_y),10),dtype=int)\n",
    "predict_xavierbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in range(len(predict_xavier_y)):\n",
    "    predict_xavierbox[j,predict_xavier_y [j]] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 1, 0],\n",
       "       [0, 1, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       ...,\n",
       "       [0, 0, 0, ..., 0, 0, 0],\n",
       "       [1, 0, 0, ..., 0, 0, 0],\n",
       "       [0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 200,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_xavierbox"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9726666666666667"
      ]
     },
     "execution_count": 202,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "###Accuracy###\n",
    "accuracy_score(y_val, predict_xavierbox)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x2=list(range(snnr_xavier.n_epochs))\n",
    "plt.figure(figsize=(15,10))\n",
    "plt.scatter(x2,snnr_xavier.loss, label='train')\n",
    "plt.scatter(x2, snnr_xavier.val_loss, label='val')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
