{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 深層学習スクラッチ　畳み込みニューラルネットワーク"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "#基本ライブラリ\n",
    "import time\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#データセット\n",
    "#from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n",
      "(48000, 10)\n",
      "(12000, 10)\n"
     ]
    }
   ],
   "source": [
    "#MNISTデータセット\n",
    "from keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()\n",
    "\n",
    "#平滑化\n",
    "X_train_f = X_train.reshape(-1, 784)\n",
    "X_test_f = X_test.reshape(-1, 784)\n",
    "\n",
    "#前処理\n",
    "X_train_ff = X_train_f.astype(np.float)\n",
    "X_test_ff = X_test_f.astype(np.float)\n",
    "X_train_ff /= 255\n",
    "X_test_ff /= 255\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "\n",
    "Xt_train, Xt_val, yt_train, yt_val = train_test_split(X_train_ff, y_train_one_hot, test_size=0.2)\n",
    "print(Xt_train.shape) # (48000, 784)\n",
    "print(Xt_val.shape) # (12000, 784)\n",
    "print(yt_train.shape)\n",
    "print(yt_val.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題2】1次元畳み込み後の出力サイズの計算"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[35 50]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])\n",
    "a = np.array([0,0])\n",
    "\n",
    "for i in range(0, len(x) - len(w) + 1):\n",
    "    a[i] = np.sum(x[i: i+len(w)]*w)+b\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0\n"
     ]
    }
   ],
   "source": [
    "def N_out(N_in, P, F, S):\n",
    "    return (N_in + 2*P - F) / S + 1\n",
    "\n",
    "P = 0\n",
    "F = len(w)\n",
    "S = 1\n",
    "\n",
    "print(N_out(len(x), P, F, S))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題3】小さな配列での1次元畳み込み層の実験"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[10 20]\n"
     ]
    }
   ],
   "source": [
    "y = np.array([45, 70])\n",
    "da = y - a\n",
    "print(da)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "バイアスの傾き: 30\n"
     ]
    }
   ],
   "source": [
    "db = np.sum(da)\n",
    "print(\"バイアスの傾き:\", db)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "フィルタの傾き [ 50.  80. 110.]\n"
     ]
    }
   ],
   "source": [
    "dw = np.zeros(3)\n",
    "for i in range(2):\n",
    "    dw += x[i : i + len(w)] * da[i]\n",
    "print(\"フィルタの傾き\", dw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xの傾き: [ 30. 110. 170. 140.]\n"
     ]
    }
   ],
   "source": [
    "dx = np.zeros(len(x))\n",
    "for i in range(2):\n",
    "    dx[i : i + len(w)] += da[i] * w\n",
    "print(\"xの傾き:\", dx)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題1】チャンネル数を1に限定した1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, initializer, optimizer, pad=0, fsize=0, stride=1):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.pad = pad\n",
    "        self.fsize = fsize\n",
    "        self.stride = stride\n",
    "        self.W = initializer.W(fsize)\n",
    "        self.B = 0\n",
    "\n",
    "    def forward(self, X, w, b, init=False):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        if init:\n",
    "            self.X = X\n",
    "            self.W = w\n",
    "            self.B = b\n",
    "            self.LW = np.zeros(len(self.W))\n",
    "            self.LX = np.zeros(len(X))\n",
    "            self.A = np.zeros(int(N_out(len(X), self.pad, self.fsize, self.stride)))\n",
    "\n",
    "        for i in range(0, len(X) - len(self.W) + 1):\n",
    "            self.A[i] = np.sum(X[i : i + len(self.W)] * self.W) + self.B\n",
    "\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.LB = np.sum(dA)\n",
    "\n",
    "        for i in range(len(dA)):\n",
    "            self.LW += self.X[i : i + len(self.W)] * dA[i]\n",
    "\n",
    "        for i in range(2):\n",
    "            self.LX[i : i + len(self.W)] += dA[i] * self.W\n",
    "\n",
    "        LX = self.LX\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        # FC2 = FC2.optimizer.updata(FC2)\n",
    "        # FC2 = SGD().update(FC2)\n",
    "\n",
    "        return LX\n",
    "\n",
    "    def N_out(N_in, P, F, S):\n",
    "        return (N_in + 2 * P - F) / S + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A: [35. 50.]\n",
      "dZ: [ 30. 110. 170. 140.]\n",
      "dW: [ 50.  80. 110.]\n",
      "dB: 30\n"
     ]
    }
   ],
   "source": [
    "test = SimpleConv1d(zabi(), SGD(), pad=0, fsize=3, stride=1)\n",
    "\n",
    "x = np.array([1.0,2.0,3.0,4.0])\n",
    "w = np.array([3.0, 5.0, 7.0])\n",
    "b = np.array([1.0])\n",
    "\n",
    "A = test.forward(x, w, b, init=True)\n",
    "print(\"A:\", A)\n",
    "\n",
    "dZ = test.backward(da)\n",
    "print(\"dZ:\", dZ)\n",
    "print(\"dW:\", test.LW)\n",
    "print(\"dB:\",  test.LB)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class zabi():\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, w, input_channel=1, output_channel=1 ):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        W = np.ones((output_channel, input_channel, w))\n",
    "\n",
    "        return W\n",
    "    \n",
    "    def B(self, output_channel):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = np.arange(1, output_channel + 1) .astype(float)\n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ザビエル for Conv\n",
    "class XavierlInit():\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, w, input_channel=1, output_channel=1 ):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        xavier = 1 / np.sqrt(w)\n",
    "        W = xavier * np.random.randn((output_channel, input_channel, w))\n",
    "\n",
    "        return W\n",
    "    \n",
    "    def B(self, output_channel):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, output_channel) \n",
    "        \n",
    "        return B\n",
    "\n",
    "#ザビエル for NN\n",
    "class XavierInitializer():\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        xavier = 1 / np.sqrt(n_nodes1)\n",
    "        W = xavier * np.random.randn(n_nodes1, n_nodes2)\n",
    "\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HeInitializer():\n",
    "    def __init__(self, sigma=0.01):\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def W(self, n_nodes1, n_nodes2):\n",
    "        \"\"\"\n",
    "        重みの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes1 : int\n",
    "          前の層のノード数\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        W :\n",
    "        \"\"\"\n",
    "        he = np.sqrt( 2 / n_nodes1 )\n",
    "        W = he * np.random.randn(n_nodes1, n_nodes2)\n",
    "\n",
    "        return W\n",
    "    \n",
    "    def B(self, n_nodes2):\n",
    "        \"\"\"\n",
    "        バイアスの初期化\n",
    "        Parameters\n",
    "        ----------\n",
    "        n_nodes2 : int\n",
    "          後の層のノード数\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        B :\n",
    "        \"\"\"\n",
    "        B = self.sigma * np.random.randn(1, n_nodes2) \n",
    "        \n",
    "        return B"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.LW\n",
    "        layer.B -= self.lr*layer.LB\n",
    "\n",
    "#AdaGrad for NN\n",
    "class AdaGrad():\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        self.hw = 0\n",
    "        self.hb = 0\n",
    "        self.hw_mean=[]\n",
    "        self.hb_mean=[]\n",
    "        \n",
    "    def update(self, layer):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        self.hw += (layer.LW)**2 \n",
    "        self.hb +=  (layer.LB)**2\n",
    "        self.hw_mean.append(np.mean(self.hw))\n",
    "        self.hb_mean.append(np.mean(self.hb))\n",
    "        \n",
    "        layer.W -= self.lr / np.sqrt(self.hw + 1e-7) * layer.LW\n",
    "        layer.B -= self.lr / np.sqrt(self.hb + 1e-7) * layer.LB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題4】チャンネル数を限定しない1次元畳み込み層クラスの作成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "class relu:\n",
    "    def __init__(self):\n",
    "        self.mask = None\n",
    "\n",
    "    def forward(self, X):\n",
    "        self.mask = X <= 0\n",
    "        self.mask = self.mask.reshape(1, -1)\n",
    "        return np.maximum(0, X)\n",
    "\n",
    "    def backward(self, LZ, A):\n",
    "        LZ[self.mask] = 0\n",
    "        dx = LZ\n",
    "        return dx\n",
    "\n",
    "\n",
    "class Tanh:\n",
    "    \"\"\"\n",
    "    ハイパボリックタンジェント関数\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, X):\n",
    "        return np.tanh(X)\n",
    "\n",
    "    def backward(self, LZ, A):\n",
    "        return LZ * (1 - np.tanh(A) ** 2)\n",
    "\n",
    "\n",
    "class Softmax:\n",
    "    \"\"\"\n",
    "    ソフトマックス関数\n",
    "    \"\"\"\n",
    "\n",
    "    def forward(self, X):\n",
    "        c = np.max(X, axis=1)\n",
    "        exp_x = np.exp(X - c.reshape(-1, 1))  # オーバーフロー対策\n",
    "        sum_exp_x = np.sum(exp_x, axis=1)\n",
    "        y = exp_x / sum_exp_x.reshape(-1, 1)\n",
    "\n",
    "        return y\n",
    "\n",
    "    def backward(self, X):\n",
    "        print(\"Softmax backward isn't made yet\")\n",
    "        pass\n",
    "\n",
    "\n",
    "class FC:\n",
    "    \"\"\"\n",
    "    ノード数n_nodes1からn_nodes2への全結合層\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_nodes1 : int\n",
    "      前の層のノード数\n",
    "    n_nodes2 : int\n",
    "      後の層のノード数\n",
    "    initializer : 初期化方法のインスタンス\n",
    "    optimizer : 最適化手法のインスタンス\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_nodes1, n_nodes2, initializer, optimizer, def_name=None):\n",
    "        self.optimizer = optimizer\n",
    "        # 初期化\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1, n_nodes2)\n",
    "        self.B = initializer.B(n_nodes2)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"\n",
    "        フォワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            入力\n",
    "        Returns\n",
    "        ----------\n",
    "        A : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            出力\n",
    "        \"\"\"\n",
    "        XW = np.dot(X, self.W)\n",
    "        self.A = XW + self.B\n",
    "\n",
    "        return self.A\n",
    "\n",
    "    def backward(self, dA, Z, FC_num):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        if FC_num == 0:\n",
    "            self.LB = np.sum(dA, axis=0)\n",
    "            self.LW = np.dot(Z.T, self.LA)\n",
    "            dZ = np.dot(self.LA, self.W.T)\n",
    "        else:\n",
    "            self.LB = np.sum(dA, axis=0)\n",
    "            self.LW = np.dot(Z.T, self.LA)\n",
    "            dZ = np.dot(self.LA, self.W.T)\n",
    "\n",
    "        # 更新\n",
    "        self = self.optimizer.update(self)\n",
    "        # FC2 = FC2.optimizer.updata(FC2)\n",
    "        # FC2 = SGD().update(FC2)\n",
    "\n",
    "        return dZ\n",
    "\n",
    "\n",
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練用データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, X, y, batch_size=20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0] / self.batch_size).astype(np.int)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "\n",
    "    def __getitem__(self, item):\n",
    "        p0 = item * self.batch_size\n",
    "        p1 = item * self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]\n",
    "\n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter * self.batch_size\n",
    "        p1 = self._counter * self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScratchDeepNeuralNetrowkClassifier:\n",
    "    \"\"\"\n",
    "    多層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes_num_list,\n",
    "        ac_list,\n",
    "        initialize_list,\n",
    "        opt_list,\n",
    "        itr=1000,\n",
    "        verbose=True,\n",
    "        lr=0.00001,\n",
    "        sigma=0.01,\n",
    "        b_size=20,\n",
    "    ):\n",
    "        self.verbose = verbose\n",
    "        self.itr = itr\n",
    "        self.lr = lr  # 学習率\n",
    "        self.sigma = sigma  # ガウス分布の標準偏差\n",
    "        self.b_size = b_size\n",
    "        self.L = []\n",
    "        self.FC = {}  # 各レイヤー格納辞書\n",
    "        self.network = len(nodes_num_list)\n",
    "        self.n_nodes = {i: nodes_num_list[i] for i in range(self.network)}\n",
    "        self.activation = {i: ac_list[i] for i in range(self.network)}\n",
    "        self.initialize_list = initialize_list\n",
    "        for i in range(len(self.initialize_list)):\n",
    "            self.initialize_list[i].sigma = self.sigma\n",
    "        self.opt_list = opt_list\n",
    "        for i in range(len(self.opt_list)):\n",
    "            self.opt_list[i].lr = self.lr\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        # 各レイヤーインスタンス化\n",
    "        Z, LZ = [], []\n",
    "        for i in range(self.network):\n",
    "            if i == 0:\n",
    "                self.FC[i] = FC(\n",
    "                    X.shape[1],\n",
    "                    self.n_nodes[i],\n",
    "                    self.initialize_list[i],\n",
    "                    self.opt_list[i],\n",
    "                )\n",
    "            else:\n",
    "                self.FC[i] = FC(\n",
    "                    self.n_nodes[i - 1],\n",
    "                    self.n_nodes[i],\n",
    "                    self.initialize_list[i],\n",
    "                    self.opt_list[i],\n",
    "                )\n",
    "            Z.append(np.array([]))\n",
    "            LZ.append(np.array([]))\n",
    "\n",
    "        # エポック\n",
    "        itr_count = 0\n",
    "        for _ in range(self.itr):\n",
    "            if itr_count % 10 == 0:\n",
    "                print(itr_count, \">\", end=\"\")\n",
    "            Lbatch = np.array([])\n",
    "\n",
    "            get_mini_batch = GetMiniBatch(X, y, batch_size=self.b_size)\n",
    "            for mini_X_train, mini_y_train in get_mini_batch:\n",
    "\n",
    "                \"\"\"フォワード\n",
    "                \"\"\"\n",
    "                for i in range(self.network):\n",
    "                    if i == 0:\n",
    "                        A = self.FC[i].forward(mini_X_train)\n",
    "                        Z[i] = self.activation[i].forward(A)\n",
    "                    else:\n",
    "                        A = self.FC[i].forward(Z[i - 1])\n",
    "                        Z[i] = self.activation[i].forward(A)\n",
    "\n",
    "                \"\"\"バックプロパゲーション\n",
    "                \"\"\"\n",
    "                for i in range(self.network)[::-1]:\n",
    "                    if i == self.network - 1:  # 出力層\n",
    "                        self.FC[i].LA = Z[i] - mini_y_train\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA, Z[i - 1], i)\n",
    "                    elif i == 0:  # 入力層\n",
    "                        self.FC[i].LA = self.activation[i].backward(\n",
    "                            LZ[i + 1], self.FC[i].A\n",
    "                        )\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA, mini_X_train, i)\n",
    "                    else:  # 隠れ層\n",
    "                        self.FC[i].LA = self.activation[i].backward(\n",
    "                            LZ[i + 1], self.FC[i].A\n",
    "                        )\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA, Z[i - 1], i)\n",
    "\n",
    "                \"\"\"損失関数\n",
    "                \"\"\"\n",
    "                Ltmp = 0\n",
    "                for i in range(self.b_size):\n",
    "                    Ltmp += np.sum(mini_y_train[i] * np.log(Z[-1][i]))\n",
    "                Lbatch = np.append(Lbatch, (Ltmp / self.b_size) * -1)\n",
    "\n",
    "            self.L.append(Lbatch.mean())\n",
    "            itr_count += 1\n",
    "            # print(\"---end of epoc---\")\n",
    "\n",
    "        if self.verbose:\n",
    "            # verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, Xt):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pZ = []\n",
    "        for i in range(self.network):\n",
    "            pZ.append(np.array([]))\n",
    "\n",
    "        for i in range(self.network):\n",
    "            if i == 0:\n",
    "                A = self.FC[i].forward(Xt)\n",
    "                pZ[i] = self.activation[i].forward(A)\n",
    "            else:\n",
    "                A = self.FC[i].forward(pZ[i - 1])\n",
    "                pZ[i] = self.activation[i].forward(A)\n",
    "\n",
    "        return pZ[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "nodes_num_list = [100, 400, 200, 100, 10]\n",
    "ac_list = [relu(), relu(), relu(), relu(), Softmax()]\n",
    "initialize_list = [\n",
    "    HeInitializer(),\n",
    "    HeInitializer(),\n",
    "    HeInitializer(),\n",
    "    HeInitializer(),\n",
    "    XavierInitializer(),\n",
    "]\n",
    "opt_list = [AdaGrad(), AdaGrad(), AdaGrad(), AdaGrad(), AdaGrad()]\n",
    "\n",
    "SDNN = ScratchDeepNeuralNetrowkClassifier(\n",
    "    nodes_num_list, ac_list, initialize_list, opt_list, itr=20, b_size=100, lr=0.01\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SDNN.fit(Xt_train, yt_train)\n",
    "plt.plot(SDNN.L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 【問題8】学習と推定"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "隠れ層２層の内、前１層をConvに"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_Conv1d:\n",
    "    \n",
    "    def __init__(self, initializer, optimizer, fsize, in_channel=1, out_channel=1, pad=0, stride=1):\n",
    "        self.optimizer = optimizer\n",
    "        self.initializer = initializer\n",
    "        self.in_channel = in_channel\n",
    "        self.out_channel = out_channel\n",
    "        self.pad = pad\n",
    "        self.fsize = fsize   #1次元\n",
    "        self.stride = stride\n",
    "        self.B = 0\n",
    "    \n",
    "    def init(self, X):\n",
    "        \"\"\"\n",
    "        Xは二次元を想定\n",
    "        \"\"\"\n",
    "        self.X = self.pad_init(X, self.pad)\n",
    "        self.W =  self.initializer.W(1, self.fsize)\n",
    "        self.B = self.initializer.B(1)\n",
    "        self.LB = np.zeros(self.B.shape)\n",
    "        self.LW = np.zeros(self.W.shape)\n",
    "        self.dZ = np.zeros(self.X.shape)\n",
    "        self.A = np.zeros((X.shape[0], int(self.N_out(X.shape[1], self.pad, self.fsize, self.stride))))\n",
    "        self.LA = np.copy(self.A)\n",
    "\n",
    "    def forward(self, X, index):\n",
    "        \"\"\"\n",
    "        Xは１次元を想定\n",
    "        \"\"\"\n",
    "        for i in range(0, len(X) - self.W.shape[1] + 1):\n",
    "            self.A[index, i] = np.sum(X[i: i+self.W.shape[1]] * self.W)+self.B        \n",
    "        \n",
    "        return self.A[index]\n",
    "    \n",
    "    def backward(self, dA, index):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        self.LB = np.sum(dA)\n",
    "        \n",
    "        for i in range(len(dA)):\n",
    "            self.LW += (self.X[index, i: i+self.W.shape[1]] * dA[i])\n",
    "        \n",
    "        for i in range(len(dA)):\n",
    "            self.dZ[index, i: i + self.W.shape[1]] += dA[i]*self.W.flatten()\n",
    "        \n",
    "        dZ = self.dZ\n",
    "        \n",
    "        self = self.optimizer.update(self, index)\n",
    "\n",
    "        \n",
    "        return dZ\n",
    "    \n",
    "    def N_out(self, N_in, P, F, S):\n",
    "        return (N_in + 2*P - F) / S + 1\n",
    "\n",
    "    def pad_init(self, X, pad):\n",
    "        \"\"\"\n",
    "        １次元方向にパディングを追加する関数\n",
    "        \"\"\"\n",
    "        for i in range(pad):\n",
    "            X = np.insert(X, 0, 0, axis=1)\n",
    "            X = np.insert(X, X.shape[1], 0, axis=1)\n",
    "        \n",
    "        return X\n",
    "\n",
    "class NN_SGD:\n",
    "    \"\"\"\n",
    "    確率的勾配降下法\n",
    "    Parameters\n",
    "    ----------\n",
    "    lr : 学習率\n",
    "    \"\"\"\n",
    "    def __init__(self, lr=0.01):\n",
    "        self.lr = lr\n",
    "        \n",
    "    def update(self, layer, index):\n",
    "        \"\"\"\n",
    "        ある層の重みやバイアスの更新\n",
    "        Parameters\n",
    "        ----------\n",
    "        layer : 更新前の層のインスタンス\n",
    "        \"\"\"\n",
    "        layer.W -= self.lr*layer.LW\n",
    "        layer.B -= self.lr*layer.LB\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Scratch1dCNNClassifier:\n",
    "    \"\"\"\n",
    "    多層ニューラルネットワーク分類器\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        nodes_num_list,\n",
    "        ac_list,\n",
    "        initialize_list,\n",
    "        opt_list,\n",
    "        itr=1000,\n",
    "        verbose=True,\n",
    "        lr=0.00001,\n",
    "        sigma=0.01,\n",
    "        b_size=20,\n",
    "    ):\n",
    "        self.verbose = verbose\n",
    "        self.itr = itr\n",
    "        self.lr = lr  # 学習率\n",
    "        self.sigma = sigma  # ガウス分布の標準偏差\n",
    "        self.b_size = b_size\n",
    "        self.L = []\n",
    "        self.FC = {}  # 各レイヤー格納辞書\n",
    "        self.network = len(nodes_num_list)\n",
    "        self.n_nodes = {i: nodes_num_list[i] for i in range(self.network)}\n",
    "        self.activation = {i: ac_list[i] for i in range(self.network)}\n",
    "        self.initialize_list = initialize_list\n",
    "        for i in range(len(self.initialize_list)):\n",
    "            self.initialize_list[i].sigma = self.sigma\n",
    "        self.opt_list = opt_list\n",
    "        for i in range(len(self.opt_list)):\n",
    "            self.opt_list[i].lr = self.lr\n",
    "\n",
    "    def fit(self, X, y, X_val=None, y_val=None):\n",
    "        \"\"\"\n",
    "        ニューラルネットワーク分類器を学習する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            訓練用データの特徴量\n",
    "        y : 次の形のndarray, shape (n_samples, )\n",
    "            訓練用データの正解値\n",
    "        X_val : 次の形のndarray, shape (n_samples, n_features)\n",
    "            検証用データの特徴量\n",
    "        y_val : 次の形のndarray, shape (n_samples, )\n",
    "            検証用データの正解値\n",
    "        \"\"\"\n",
    "        # 各レイヤーインスタンス化\n",
    "        Z, LZ = [], []\n",
    "        for i in range(self.network):\n",
    "            if i == 0:\n",
    "                self.FC[i] = NN_Conv1d(\n",
    "                    self.initialize_list[i],\n",
    "                    self.opt_list[i],\n",
    "                    fsize=385,\n",
    "                    in_channel=1,\n",
    "                    out_channel=1,\n",
    "                    pad=0,\n",
    "                )\n",
    "            else:\n",
    "                self.FC[i] = FC(\n",
    "                    self.n_nodes[i - 1],\n",
    "                    self.n_nodes[i],\n",
    "                    self.initialize_list[i],\n",
    "                    self.opt_list[i],\n",
    "                )\n",
    "            Z.append(np.array([]))\n",
    "            LZ.append(np.array([]))\n",
    "\n",
    "        # エポック\n",
    "        itr_count = 0\n",
    "        self.FC[0].init(X)\n",
    "        for _ in range(self.itr):\n",
    "            if itr_count % 2 == 0:\n",
    "                print(itr_count, \">>>>>>\", end=\"\")\n",
    "            Lbatch = np.array([])\n",
    "            index = 0\n",
    "\n",
    "            for mini_X_train, mini_y_train in zip(X, y):\n",
    "\n",
    "                \"\"\"フォワード\n",
    "                \"\"\"\n",
    "                for i in range(self.network):\n",
    "                    if i == 0:\n",
    "                        A = self.FC[i].forward(mini_X_train, index)\n",
    "                        Z[i] = self.activation[i].forward(A).reshape(1, 400)\n",
    "\n",
    "                    else:\n",
    "                        A = self.FC[i].forward(Z[i - 1])\n",
    "                        Z[i] = self.activation[i].forward(A)\n",
    "\n",
    "                \"\"\"バックプロパゲーション\n",
    "                \"\"\"\n",
    "                for i in range(self.network)[::-1]:\n",
    "                    if i == self.network - 1:  # 出力層\n",
    "                        self.FC[i].LA = Z[i] - mini_y_train\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA, Z[i - 1], i)\n",
    "                    elif i == 0:  # Conv層\n",
    "                        self.FC[i].LA[index] = self.activation[i].backward(\n",
    "                            LZ[i + 1], self.FC[i].A[index]\n",
    "                        )\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA[index], index)\n",
    "                    else:  # 隠れ層\n",
    "                        self.FC[i].LA = self.activation[i].backward(\n",
    "                            LZ[i + 1], self.FC[i].A\n",
    "                        )\n",
    "                        LZ[i] = self.FC[i].backward(self.FC[i].LA, Z[i - 1], i)\n",
    "\n",
    "                \"\"\"損失関数\n",
    "                \"\"\"\n",
    "                Ltmp = 0\n",
    "                for i in range(self.b_size):\n",
    "                    Ltmp += np.sum(mini_y_train[i] * np.log(Z[-1][i]))\n",
    "                Lbatch = np.append(Lbatch, (Ltmp / self.b_size) * -1)\n",
    "                index += 1\n",
    "\n",
    "            self.L.append(Lbatch.mean())\n",
    "            itr_count += 1\n",
    "            # print(\"---end of epoc---\")\n",
    "\n",
    "        if self.verbose:\n",
    "            # verboseをTrueにした際は学習過程などを出力する\n",
    "            print()\n",
    "        pass\n",
    "\n",
    "    def predict(self, Xt):\n",
    "        \"\"\"\n",
    "       ニューラルネットワーク分類器を使い推定する。\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : 次の形のndarray, shape (n_samples, n_features)\n",
    "            サンプル\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            次の形のndarray, shape (n_samples, 1)\n",
    "            推定結果\n",
    "        \"\"\"\n",
    "        pZ = []\n",
    "        for i in range(self.network):\n",
    "            pZ.append(np.array([]))\n",
    "\n",
    "        index = 0\n",
    "        for mini_X in Xt:\n",
    "            for i in range(self.network):\n",
    "                if i == 0:\n",
    "                    A = self.FC[i].forward(Xt, index)\n",
    "                    pZ[i] = self.activation[i].forward(A).reshape(1, 400)\n",
    "                elif i == 2:\n",
    "                    A = self.FC[i].forward(pZ[i - 1])\n",
    "                    pZ[i] = np.append(pZ[i], self.activation[i].forward(A))\n",
    "                else:\n",
    "                    A = self.FC[i].forward(pZ[i - 1])\n",
    "                    pZ[i] = self.activation[i].forward(A)\n",
    "\n",
    "            index += 1\n",
    "\n",
    "        return pZ[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 >>>>>>2 >>>>>>4 >>>>>>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc5a1fd3c90>]"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Xt_train1d = Xt_train[0:5000]\n",
    "yt_train1d = yt_train[0:5000]\n",
    "\n",
    "nodes_num_list = [400, 200, 10]\n",
    "ac_list = [relu(), relu(), Softmax()]\n",
    "initialize_list = [XavierInitializer(), HeInitializer(), XavierInitializer()]\n",
    "opt_list = [NN_SGD(), AdaGrad(), AdaGrad()]\n",
    "\n",
    "CNN = Scratch1dCNNClassifier(\n",
    "    nodes_num_list, ac_list, initialize_list, opt_list, itr=5, b_size=1, lr=0.0001\n",
    ")\n",
    "CNN.fit(Xt_train1d, yt_train1d)\n",
    "plt.plot(CNN.L)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2.216816818759459,\n",
       " 2.182934242593131,\n",
       " 2.182932249494254,\n",
       " 2.182930709177787,\n",
       " 2.182929429623384]"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CNN.L"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetMiniBatch:\n",
    "    \"\"\"\n",
    "    ミニバッチを取得するイテレータ\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    X : 次の形のndarray, shape (n_samples, n_features)\n",
    "      訓練データ\n",
    "    y : 次の形のndarray, shape (n_samples, 1)\n",
    "      正解値\n",
    "    batch_size : int\n",
    "      バッチサイズ\n",
    "    seed : int\n",
    "      NumPyの乱数のシード\n",
    "    \"\"\"\n",
    "    def __init__(self, X, y, batch_size = 20, seed=0):\n",
    "        self.batch_size = batch_size\n",
    "        np.random.seed(seed)\n",
    "        shuffle_index = np.random.permutation(np.arange(X.shape[0]))\n",
    "        self._X = X[shuffle_index]\n",
    "        self._y = y[shuffle_index]\n",
    "        self._stop = np.ceil(X.shape[0]/self.batch_size).astype(np.int)\n",
    "    def __len__(self):\n",
    "        return self._stop\n",
    "    def __getitem__(self,item):\n",
    "        p0 = item*self.batch_size\n",
    "        p1 = item*self.batch_size + self.batch_size\n",
    "        return self._X[p0:p1], self._y[p0:p1]        \n",
    "    def __iter__(self):\n",
    "        self._counter = 0\n",
    "        return self\n",
    "    def __next__(self):\n",
    "        if self._counter >= self._stop:\n",
    "            raise StopIteration()\n",
    "        p0 = self._counter*self.batch_size\n",
    "        p1 = self._counter*self.batch_size + self.batch_size\n",
    "        self._counter += 1\n",
    "        return self._X[p0:p1], self._y[p0:p1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import mnist\n",
    "(X_train, y_train), (X_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 28, 28)\n",
      "(10000, 28, 28)\n",
      "uint8\n",
      "[[  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   3  18  18  18 126 136\n",
      "  175  26 166 255 247 127   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  30  36  94 154 170 253 253 253 253 253\n",
      "  225 172 253 242 195  64   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  49 238 253 253 253 253 253 253 253 253 251\n",
      "   93  82  82  56  39   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0  18 219 253 253 253 253 253 198 182 247 241\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  80 156 107 253 253 205  11   0  43 154\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0  14   1 154 253  90   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0 139 253 190   2   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0  11 190 253  70   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  35 241 225 160 108   1\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0  81 240 253 253 119\n",
      "   25   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  45 186 253 253\n",
      "  150  27   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0  16  93 252\n",
      "  253 187   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0 249\n",
      "  253 249  64   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0  46 130 183 253\n",
      "  253 207   2   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0  39 148 229 253 253 253\n",
      "  250 182   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0  24 114 221 253 253 253 253 201\n",
      "   78   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0  23  66 213 253 253 253 253 198  81   2\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0  18 171 219 253 253 253 253 195  80   9   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0  55 172 226 253 253 253 253 244 133  11   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0 136 253 253 253 212 135 132  16   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]\n",
      " [  0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0   0\n",
      "    0   0   0   0   0   0   0   0   0   0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape) # (60000, 28, 28)\n",
    "print(X_test.shape) # (10000, 28, 28)\n",
    "print(X_train[0].dtype) # uint8\n",
    "print(X_train[0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "index = 0\n",
    "image = X_train[index].reshape(28,28)\n",
    "#X_train[index]: (784,)\n",
    "# image: (28, 28)\n",
    "plt.imshow(image, 'gray', vmin = 0, vmax = 255)\n",
    "plt.title('label : {}'.format(y_train[index]))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "X_train = X_train.astype(np.float)\n",
    "X_test = X_test.astype(np.float)\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "print(X_train.max()) # 1.0\n",
    "print(X_train.min()) # 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000,)\n",
      "(60000, 10)\n",
      "float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "enc = OneHotEncoder(handle_unknown='ignore', sparse=False)\n",
    "y_train_one_hot = enc.fit_transform(y_train[:, np.newaxis])\n",
    "y_test_one_hot = enc.transform(y_test[:, np.newaxis])\n",
    "print(y_train.shape) # (60000,)\n",
    "print(y_train_one_hot.shape) # (60000, 10)\n",
    "print(y_train_one_hot.dtype) # float64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(48000, 784)\n",
      "(12000, 784)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train_one_hot, test_size=0.2)\n",
    "print(X_train.shape) # (48000, 784)\n",
    "print(X_val.shape) # (12000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleConv1d:\n",
    "    def __init__(self, weight, bias):\n",
    "        self.weight = weight\n",
    "        self.bias = bias\n",
    "        \n",
    "        \n",
    "    def forward(self, x):#X入ってくる\n",
    "        self.x = x\n",
    "        predict = np.zeros([self.x.shape[0]-2, self.weight.shape[0]])\n",
    "        \n",
    "        roop = self.x.shape[0]-self.weight.shape[0] + 1\n",
    "\n",
    "        index = np.arange(self.weight.shape[0])\n",
    "        \n",
    "        self.predict_list = []\n",
    "        \n",
    "        for i in range(roop):\n",
    "            \n",
    "            predict = int(np.dot(self.x[index + i],self.weight) + self.bias)\n",
    "            self.predict_list.append(predict)\n",
    "            \n",
    "        return self.predict_list\n",
    "    \n",
    "    def backward(self,x):\n",
    "        delta_a = np.array([10, 20]) #誤差\n",
    "        delta_B = np.sum(self.predict_list)\n",
    "        self.delta_W_list =[]# np.zeros(self.weight)\n",
    "        \n",
    "        self.delta_W0_list = self.weight.tolist()\n",
    "        self.delta_W0_list.append(0)\n",
    "        self.delta_W0_list.insert(0, 0)\n",
    "        self.delta_X_list = []\n",
    "        \n",
    "        #delta_W\n",
    "        for j in range(self.weight.shape[0]):\n",
    "            delta_W =  (delta_a[0]*self.x[j]) +   (delta_a[1]*self.x[j + 1]) \n",
    "            print(delta_W)\n",
    "            self.delta_W_list.append(delta_W)\n",
    "            \n",
    "        #delta_X\n",
    "        for k in range(self.x.shape[0]):\n",
    "            delta_X = (delta_a[0]*self.delta_W0_list[k+1]) +   (delta_a[1]*self.delta_W0_list[k])\n",
    "            self.delta_X_list.append(delta_X)\n",
    "        return self.delta_X_list\n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "b = np.array([1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "イニシャライザー"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Xavierをインスタンス化するときはXavier(self.n_nodes)とする\n",
    "\n",
    "class Xavier:\n",
    "    def __init__(self, n_nodes1):\n",
    "        self.n_nodes1= n_nodes1\n",
    "        self.sigma = 1/np.sqrt(self.n_nodes1)\n",
    "               \n",
    "    def W(self, n_nodes1): #フィルタ\n",
    "        return self.sigma*np.random.randn(n_nodes1)\n",
    "    \n",
    "    def B(self, n_nodes2): #1?\n",
    "        return  self.sigma * np.random.randn(n_nodes2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "XXX = Xavier(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.22305639, -0.31210672,  0.2333637 ])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XXX.W(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 11)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<tokenize>\"\u001b[0;36m, line \u001b[0;32m11\u001b[0m\n\u001b[0;31m    def forward(self, Z):\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "class SimpleConv1d:\n",
    " \n",
    "     def __init__(self, n_nodes1, n_nodes2, initializer, optimizer):\n",
    "        # 初期化\n",
    "        self.optimizer = optimizer\n",
    "        # initializerのメソッドを使い、self.Wとself.Bを初期化する\n",
    "        self.W = initializer.W(n_nodes1)#?\n",
    "        self.B =  initializer.B(n_nodes2)#?\n",
    "        pass\n",
    "        \n",
    "    def forward(self, Z):\n",
    "        self.Z = Z.copy()\n",
    "        return np.dot(Z, self.W) + self.B #output=A\n",
    "        \n",
    "\n",
    "\n",
    "    def backward(self, dA):\n",
    "        \"\"\"\n",
    "        バックワード\n",
    "        Parameters\n",
    "        ----------\n",
    "        dA : 次の形のndarray, shape (batch_size, n_nodes2)\n",
    "            後ろから流れてきた勾配\n",
    "        Returns\n",
    "        ----------\n",
    "        dZ : 次の形のndarray, shape (batch_size, n_nodes1)\n",
    "            前に流す勾配\n",
    "        \"\"\"\n",
    "        \n",
    "        self.dB = dA #b3grad = delta1=dA\n",
    "        #print(self.Z.shape)\n",
    "        #print(dA.shape)\n",
    "        self.dW = np.dot(self.Z.T,dA) #np.dot(___Z2___, dA)shapedW?? = np.dot(self.Z,dA) のshape確認\n",
    "        \n",
    "        dZ = np.dot(dA, self.W.T)#(np.dot(delta1,self.W3.T)\n",
    "        \n",
    "        # 更新\n",
    "        self = self.optimizer.update(self) #??????\n",
    "        return dZ\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ScrachDeepNeuralNetworkRegressor():\n",
    "    \n",
    "    def __init__(self, n_epochs, batch, alpha = np.exp(-7), sigma = 0.01, n_nodes1 = 400, n_nodes2 = 200, n_output = 10):\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch = batch\n",
    "        self.n_nodes1 = n_nodes1\n",
    "        self.n_nodes2 = n_nodes2\n",
    "        self.n_output = n_output\n",
    "        self.loss = []#np.zeros(n_epochs)\n",
    "        self.val_loss = []#np.zeros(n_epochs)\n",
    "        self.alpha = alpha\n",
    "        self.sigma = sigma\n",
    "        \n",
    "    def fit(self, X, y, X_val=None, y_val=None, val=False):\n",
    "\n",
    "        self.X = X\n",
    "        self.y = y\n",
    "        self.n_features = self.X.shape[1]\n",
    "        train_minibatch = GetMiniBatch(self.X, y, self.batch)\n",
    "        test_minibatch = GetMiniBatch(X_val, y_val, self.batch)\n",
    "        \n",
    "        optimizer = SGD(self.alpha)\n",
    "        #optimizer1 = AdaGrad(self.alpha)\n",
    "        self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC1 = FC(self.n_features, self.n_nodes1, SimpleInitializer(self.sigma), optimizer1)\n",
    "        #self.activation1 = Tanh()\n",
    "        self.activation1 = ReLU()\n",
    "        #optimizer2 = AdaGrad(self.alpha)\n",
    "        self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC2 = FC(self.n_nodes1, self.n_nodes2, SimpleInitializer(self.sigma), optimizer2)\n",
    "        #self.activation2 = Tanh()\n",
    "        self.activation2 = ReLU()\n",
    "        #optimizer3 = AdaGrad(self.alpha)\n",
    "        self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer)\n",
    "        #self.FC3 = FC(self.n_nodes2, self.n_output, SimpleInitializer(self.sigma), optimizer3)\n",
    "        self.activation3 = Softmax_with_crossentropyloss()\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            for mini_X, mini_y in train_minibatch:\n",
    "                X = mini_X\n",
    "                y = mini_y#[:,np.newaxis] ############\n",
    "                #フォワード\n",
    "                A1 = self.FC1.forward(X)\n",
    "                Z1 = self.activation1.forward(A1) #Tanh().forward()\n",
    "                A2 = self.FC2.forward(Z1)\n",
    "                Z2 = self.activation2.forward(A2)\n",
    "                A3 = self.FC3.forward(Z2)\n",
    "                Z3 = self.activation3.forward(A3)\n",
    "                #バックワード\n",
    "                dA3 = self.activation3.backward(y) # 交差エントロピー誤差とソフトマックスを合わせている\n",
    "                dZ2 = self.FC3.backward(dA3)\n",
    "                dA2 = self.activation2.backward(dZ2)\n",
    "                dZ1 = self.FC2.backward(dA2)\n",
    "                dA1 = self.activation1.backward(dZ1)\n",
    "                dZ0 = self.FC1.backward(dA1) # dZ0は使用しない\n",
    "\n",
    "\n",
    "\n",
    "                \n",
    "        return\n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def after_out(n_in, filter_size, stride, pad):\n",
    "    n_in = n_in.shape[0]\n",
    "    out = (n_in + 2*pad - filter_size)/stride + 1\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_in = np.random.randn(4)\n",
    "n_in.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "af = after_out(n_in,3,1,0)\n",
    "af"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "入力x、重みw、バイアスbを次のようにします。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.array([1,2,3,4])\n",
    "w = np.array([3, 5, 7])\n",
    "a = np.zeros([2, 3])\n",
    "b = np.array([1])\n",
    "predict = np.zeros([x.shape[0]-2,w.shape[0]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = SimpleConv1d(w, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[35, 50]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yyy = test.forward(x)\n",
    "yyy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "80\n",
      "110\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[30, 110, 170, 140]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.backward(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 5 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(w)\n",
    "delta_W_list = np.zeros(len(w))\n",
    "delta_W_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def im2col(input_data, filter_h, filter_w, stride=1, pad=0):\n",
    "    N, C, H, W = input_data.shape\n",
    "    out_h = (H + 2*pad - filter_h)//stride + 1\n",
    "    out_w = (W + 2*pad - filter_w)//stride + 1\n",
    "\n",
    "    img = np.pad(input_data, [(0,0), (0,0), (pad, pad), (pad, pad)], 'constant')\n",
    "    col = np.zeros((N, C, filter_h, filter_w, out_h, out_w))\n",
    "\n",
    "    for y in range(filter_h):\n",
    "        y_max = y + stride*out_h\n",
    "        for x in range(filter_w):\n",
    "            x_max = x + stride*out_w\n",
    "            col[:, :, y, x, :, :] = img[:, :, y:y_max:stride, x:x_max:stride]\n",
    "\n",
    "    col = col.transpose(0, 4, 5, 1, 2, 3).reshape(N*out_h*out_w, -1)\n",
    "    return col"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(9, 75)\n"
     ]
    }
   ],
   "source": [
    "x1 = np.random.rand(1, 3, 7, 7)\n",
    "col1 = im2col(x1, 5, 5, stride=1, pad= 0)\n",
    "print(col1.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.41149353, 0.31743926, 0.57216953],\n",
       "         [0.63948939, 0.96565898, 0.87668382],\n",
       "         [0.13853787, 0.98550537, 0.50329796]],\n",
       "\n",
       "        [[0.00416114, 0.00853549, 0.09721422],\n",
       "         [0.72830055, 0.21767349, 0.06555946],\n",
       "         [0.53618484, 0.30941128, 0.30451651]],\n",
       "\n",
       "        [[0.98371654, 0.38787934, 0.15032263],\n",
       "         [0.24521961, 0.32417089, 0.43490609],\n",
       "         [0.4446306 , 0.78062791, 0.74595924]]],\n",
       "\n",
       "\n",
       "       [[[0.12540969, 0.46709371, 0.24766485],\n",
       "         [0.40123331, 0.94784044, 0.61968127],\n",
       "         [0.1837575 , 0.12612049, 0.52954342]],\n",
       "\n",
       "        [[0.60468265, 0.12788636, 0.86863193],\n",
       "         [0.92756783, 0.36762147, 0.26166019],\n",
       "         [0.34761498, 0.28644808, 0.82355617]],\n",
       "\n",
       "        [[0.12460774, 0.95175554, 0.13672596],\n",
       "         [0.41164183, 0.01345122, 0.43901727],\n",
       "         [0.32141284, 0.10460882, 0.6724505 ]]]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_random = np.random.rand(2, 3, 3, 3)\n",
    "w_random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.41149353, 0.31743926, 0.57216953, 0.63948939, 0.96565898,\n",
       "        0.87668382, 0.13853787, 0.98550537, 0.50329796, 0.00416114,\n",
       "        0.00853549, 0.09721422, 0.72830055, 0.21767349, 0.06555946,\n",
       "        0.53618484, 0.30941128, 0.30451651, 0.98371654, 0.38787934,\n",
       "        0.15032263, 0.24521961, 0.32417089, 0.43490609, 0.4446306 ,\n",
       "        0.78062791, 0.74595924],\n",
       "       [0.12540969, 0.46709371, 0.24766485, 0.40123331, 0.94784044,\n",
       "        0.61968127, 0.1837575 , 0.12612049, 0.52954342, 0.60468265,\n",
       "        0.12788636, 0.86863193, 0.92756783, 0.36762147, 0.26166019,\n",
       "        0.34761498, 0.28644808, 0.82355617, 0.12460774, 0.95175554,\n",
       "        0.13672596, 0.41164183, 0.01345122, 0.43901727, 0.32141284,\n",
       "        0.10460882, 0.6724505 ]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w_random.reshape([2,-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
